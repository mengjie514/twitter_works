{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "PSIV_EDA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMssQKt+R1wa/r7dqwnyvSp",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mengjie514/twitter_works/blob/master/PSIV_EDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwMK4j3MCvTm"
      },
      "source": [
        "**3. Exploratory Data Analysis (EDA)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "ch-rZ2-SfRvx",
        "outputId": "c956e0c7-eeb4-4bad-d093-8af1b250d301"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "os.chdir(\"/content/gdrive/My Drive/Colab Notebooks/PSIV\")\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "\n",
        "df = pd.read_excel('output_for_R_0.65.xlsx')\n",
        "df = df[['care', 'harm','fairness','cheating','loyalty','betrayal','authority','subversion', 'purity','degradation','non-moral','annotation_main','new_clean_text','new_clean_text_deep_stem','Corpus']]\n",
        "df.columns = ['care0', 'harm0','fairness0','cheating0','loyalty0','betrayal0','authority0','subversion0', 'purity0','degradation0','non-moral0','annotation_main','new_clean_text','new_clean_text_deep_stem','Corpus']\n",
        "df = df[df['new_clean_text_deep_stem'].notna()]\n",
        "df = df[df['annotation_main'].notna()]\n",
        "df.reset_index(inplace=True)\n",
        "\n",
        "# copy a df for for word counts\n",
        "df_words = df\n",
        "\n",
        "print(\"Number of rows in data =\", df.shape[0])\n",
        "print(\"Number of columns in data =\", df.shape[1])\n",
        "print(\"\\n\")\n",
        "print(\"**Sample data:**\")\n",
        "df.head(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Number of rows in data = 25794\n",
            "Number of columns in data = 16\n",
            "\n",
            "\n",
            "**Sample data:**\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>care0</th>\n",
              "      <th>harm0</th>\n",
              "      <th>fairness0</th>\n",
              "      <th>cheating0</th>\n",
              "      <th>loyalty0</th>\n",
              "      <th>betrayal0</th>\n",
              "      <th>authority0</th>\n",
              "      <th>subversion0</th>\n",
              "      <th>purity0</th>\n",
              "      <th>degradation0</th>\n",
              "      <th>non-moral0</th>\n",
              "      <th>annotation_main</th>\n",
              "      <th>new_clean_text</th>\n",
              "      <th>new_clean_text_deep_stem</th>\n",
              "      <th>Corpus</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>care</td>\n",
              "      <td>Peace and Love Prevail. God Bless.</td>\n",
              "      <td>peac love prevail god bless</td>\n",
              "      <td>ALM</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  care0  ...     new_clean_text_deep_stem  Corpus\n",
              "0  0      1.0    ...  peac love prevail god bless  ALM   \n",
              "\n",
              "[1 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTTAa9nTDIF7"
      },
      "source": [
        "**3.1 Turning annotation list into set of columns of binary data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "i2WUuxFGa3-j",
        "outputId": "4361a593-efdc-4561-af3e-9079c7024c49"
      },
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "annotation_new=[]\n",
        "\n",
        "for cell in df['annotation_main']:\n",
        "    cell=cell.replace(\" \", \"\") \n",
        "    cell=cell.replace(\"&\", \"& \") \n",
        "    annotation_new.append(cell.split(\",\"))\n",
        "\n",
        "df['annotation_new'] = annotation_new \n",
        "\n",
        "mlb = MultiLabelBinarizer() \n",
        "binary_labels=pd.DataFrame(mlb.fit_transform(df['annotation_new']),columns=mlb.classes_) \n",
        "binary_labels=binary_labels.sort_index(axis=1) \n",
        "\n",
        "df = df.join(binary_labels)\n",
        "df = df[['new_clean_text_deep_stem', 'care', 'harm','fairness','cheating','loyalty','betrayal','authority','subversion', 'purity','degradation','non-moral']]\n",
        "df.head(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>new_clean_text_deep_stem</th>\n",
              "      <th>care</th>\n",
              "      <th>harm</th>\n",
              "      <th>fairness</th>\n",
              "      <th>cheating</th>\n",
              "      <th>loyalty</th>\n",
              "      <th>betrayal</th>\n",
              "      <th>authority</th>\n",
              "      <th>subversion</th>\n",
              "      <th>purity</th>\n",
              "      <th>degradation</th>\n",
              "      <th>non-moral</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>peac love prevail god bless</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      new_clean_text_deep_stem  care  harm  ...  purity  degradation  non-moral\n",
              "0  peac love prevail god bless  1     0     ...  0       0            0        \n",
              "\n",
              "[1 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhGel5YB11Bt"
      },
      "source": [
        "**3.2 Count number of texts under each/multi labels**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "id": "hfT1rISF11Pz",
        "outputId": "1b7b4b6c-73b0-4211-f4ca-081b5d1ba7ef"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "categories = list(df.iloc[:,1:].columns.values)\n",
        "sns.set(font_scale = 2)\n",
        "plt.figure(figsize=(15,8))\n",
        "\n",
        "ax= sns.barplot(categories, df.iloc[:,1:].sum().values)\n",
        "ax.tick_params(axis = 'both', which = 'major', labelsize = 10)\n",
        "ax.tick_params(axis = 'both', which = 'minor', labelsize = 10)\n",
        "plt.ylabel('Number of Tweets', fontsize=11)\n",
        "plt.xlabel('Moral Type ', fontsize=11)\n",
        "\n",
        "rects = ax.patches\n",
        "labels = df.iloc[:,1:].sum().values\n",
        "for rect, label in zip(rects, labels):\n",
        "    height = rect.get_height()\n",
        "    ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom', fontsize=10)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4uCce1J4FsG"
      },
      "source": [
        "**3.3 Count number of texts having multi labels**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "id": "Vt35vvMx4J2x",
        "outputId": "9d6e0d38-6017-4810-a6db-b45abdb59f26"
      },
      "source": [
        "rowSums = df.iloc[:,1:].sum(axis=1)\n",
        "multiLabel_counts = rowSums.value_counts()\n",
        "multiLabel_counts = multiLabel_counts.iloc[0:]\n",
        "sns.set(font_scale = 2)\n",
        "plt.figure(figsize=(15,8))\n",
        "ax = sns.barplot(multiLabel_counts.index, multiLabel_counts.values)\n",
        "ax.tick_params(axis = 'both', which = 'major', labelsize = 10)\n",
        "ax.tick_params(axis = 'both', which = 'minor', labelsize = 10)\n",
        "plt.title(\"Tweets having Multiple Moral Labels\", fontsize=11)\n",
        "plt.ylabel('Number of Tweets', fontsize=11)\n",
        "plt.xlabel('Number of Moral Labels', fontsize=11)\n",
        "\n",
        "rects = ax.patches\n",
        "labels = multiLabel_counts.values\n",
        "for rect, label in zip(rects, labels):\n",
        "    height = rect.get_height()\n",
        "    ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom', fontsize=10)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5878VCM219IX"
      },
      "source": [
        "**3.4 Words frequency under each label**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ja5y4az6UX0",
        "outputId": "876adcd0-c350-4ff4-b873-703013cd31f1"
      },
      "source": [
        "import nltk\n",
        "\n",
        "def orig(df):\n",
        "    s = df_words[\"annotation_main\"].str.split(',').apply(pd.Series,1).stack()\n",
        "    s.index = s.index.droplevel(-1)\n",
        "    s.name = \"annotation_split\"\n",
        "    return df.join(s)\n",
        "\n",
        "df = %time orig(df.copy())\n",
        "\n",
        "# count words frequency grouped by label\n",
        "nltk.download('punkt')\n",
        "output = pd.DataFrame(df.groupby('annotation_split')['new_clean_text_deep_stem'].apply(lambda x: nltk.FreqDist(nltk.tokenize.word_tokenize(' '.join(x)))))\n",
        "output = output.reset_index().rename(columns={df.index.name:'annotation_split','level_1':'words','new_clean_text_deep_stem':'count'})\n",
        "\n",
        "output['high_freq'] = np.where(output['count'] >= 100.0, 'Y', 'N')\n",
        "\n",
        "# present high-frequent words for each label\n",
        "df_agg = output[output.high_freq == 'Y'].groupby(['annotation_split','words']).agg({'count':sum})\n",
        "g = df_agg['count'].groupby('annotation_split', group_keys=False)\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"**Count the most common words per label:**\")\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "print(g.apply(lambda x: x.sort_values(ascending=False).head(3)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 7.96 s, sys: 542 ms, total: 8.5 s\n",
            "Wall time: 7.92 s\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "\n",
            "\n",
            "**Count the most common words per label:**\n",
            "annotation_split  words   \n",
            "authority         respect     384.0 \n",
            "                  obey        351.0 \n",
            "                  law         316.0 \n",
            "betrayal          traitor     300.0 \n",
            "                  peopl       134.0 \n",
            "                  polic       107.0 \n",
            "care              sandi       608.0 \n",
            "                  love        513.0 \n",
            "                  compass     414.0 \n",
            "cheating          injustic    424.0 \n",
            "                  sandi       359.0 \n",
            "                  fraud       340.0 \n",
            "degradation       disgust     167.0 \n",
            "                  traitor     126.0 \n",
            "                  god         108.0 \n",
            "fairness          justic      1114.0\n",
            "                  equal       524.0 \n",
            "                  right       358.0 \n",
            "harm              sandi       631.0 \n",
            "                  hurt        369.0 \n",
            "                  peopl       323.0 \n",
            "loyalty           solidar     664.0 \n",
            "                  sandi       233.0 \n",
            "                  love        204.0 \n",
            "non-moral         bitch       1745.0\n",
            "                  like        713.0 \n",
            "                  hoe         645.0 \n",
            "purity            god         129.0 \n",
            "                  life        108.0 \n",
            "subversion        sandi       336.0 \n",
            "                  disobedi    157.0 \n",
            "                  civil       153.0 \n",
            "Name: count, dtype: float64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlWyVcWEer69"
      },
      "source": [
        "**4. Modelling**\n",
        "\n",
        "There exists multiple techniques how to solve a multi-label classification.\n",
        "\n",
        "**4.1 Problem Transformation**\n",
        "\n",
        "Divide the multi-label problem into one or more conventional single-label problems:\n",
        "\n",
        "*   Binary classification transformation (OneVsRest) — to divide the problem into several independent binary classification tasks\n",
        "*   Classifer Chain (ClassifierChain) — similar to binary relevance, difference being it forms chains in order to preserve label correlation\n",
        "*    Multi-class classification transformation (Label Powerset) — map out each combination of labels into a single label and trains a single label classifier\n",
        "\n",
        "**4.2 Word Embedding**\n",
        "\n",
        "There are different techniques to extract information from raw text data and use it to train a classification model:\n",
        "\n",
        "*   The Bag-of-Words model builds a vocabulary from a corpus of documents and counts how many times the words appear in each document.\n",
        "*   Instead of simple counting, uses the term frequency–inverse document frequency (or Tf–Idf) is intended to reflect how important a word is to a document in a collection or corpus.\n",
        "*   Word2Vec produces a vector space, typically of several hundred dimensions, with each unique word in the corpus such that words that share common contexts in the corpus are located close to one another in the space.\n",
        "*   GloVe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAKOEg4i9qDJ",
        "outputId": "37917cdf-580c-4510-f3ca-9ce338a59f41"
      },
      "source": [
        "! pip install scikit-multilearn\n",
        "import sklearn\n",
        "from sklearn import feature_extraction\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, roc_curve, confusion_matrix, multilabel_confusion_matrix, classification_report\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from skmultilearn.problem_transform import ClassifierChain, LabelPowerset\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "\n",
        "seeds = [1, 43, 678, 90, 135]\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['new_clean_text_deep_stem'], \n",
        "                                                    df.drop(['new_clean_text_deep_stem'], axis=1),\n",
        "                                                    test_size=0.3, \n",
        "                                                    random_state=seeds[0],\n",
        "                                                    shuffle=True)\n",
        "print(X_train.shape,y_train.shape)\n",
        "print(X_test.shape,y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-multilearn in /usr/local/lib/python3.7/dist-packages (0.2.0)\n",
            "(18055,) (18055, 11)\n",
            "(7739,) (7739, 11)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oa0QDS7OBR2e",
        "outputId": "462be8a9-bb1d-4d98-9859-86550e7f4d81"
      },
      "source": [
        "##Classic BoW\n",
        "vectorizer = feature_extraction.text.CountVectorizer(max_features=5000)\n",
        "vectorizer.fit(X_train)\n",
        "\n",
        "X_train = vectorizer.transform(X_train)\n",
        "X_test = vectorizer.transform(X_test)\n",
        "\n",
        "labels = ['care', 'harm', 'fairness', 'cheating', 'loyalty', 'betrayal', 'authority', 'subversion', 'purity', 'degradation', 'non-moral'] \n",
        "\n",
        "def run_pipeline(pipeline, X_train, y_train, X_test, y_test):\n",
        "    pipeline.fit(X_train, y_train)\n",
        "    predictions = pipeline.predict(X_test)\n",
        "    print(roc_auc_score(y_test, predictions)) # or + average = 'samples'; roc_auc_score(y_test, predictions.toarray()) for ClassifierChain\n",
        "    #print(classification_report(y_test, predictions, target_names=labels))\n",
        "\n",
        "run_pipeline(Pipeline([('clf', MultiOutputClassifier(MultinomialNB()))]), # MultinomialNB vs. LogisticRegression(solver='sag') vs. LinearSVC vs. RandomForestClassifier vs. xgb.XGBClassifier\n",
        "             X_train, y_train, X_test, y_test)                                  # OneVsRestClassifier (n_jobs = -1) vs. ClassifierChain vs. MultiOutputClassifier"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7706741107643663\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwK7YVgf4gyr"
      },
      "source": [
        "##Tf-Idf\n",
        "vectorizer = TfidfVectorizer(max_features=5000, strip_accents='unicode', analyzer='word', ngram_range=(1,3), norm='l2')\n",
        "vectorizer.fit(X_train)\n",
        "\n",
        "X_train = vectorizer.transform(X_train)\n",
        "X_test = vectorizer.transform(X_test)\n",
        "\n",
        "run_pipeline(Pipeline([('clf', ClassifierChain(MultinomialNB()))]), \n",
        "             X_train, y_train, X_test, y_test)               "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEpiTF72iD63"
      },
      "source": [
        "##Word embedding (Word2Vec)\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "combined_df = X_train.append(X_test)\n",
        "\n",
        "Vocab_list = (combined_df.apply(lambda x:str(x).strip().split()))\n",
        "models = Word2Vec(Vocab_list,size=100)\n",
        "WordVectorz = dict(zip(models.wv.index2word,models.wv.vectors))\n",
        "\n",
        "#fit these things into a pipeline\n",
        "class AverageEmbeddingVectorizer(object):\n",
        "    def __init__(self, word2vec):\n",
        "        self.word2vec = word2vec\n",
        "        # if a text is empty we should return a vector of zeros\n",
        "        # with the same dimensionality as all the other vectors\n",
        "        self.dim = 100 # as we use 100 embedding points \n",
        "\n",
        "    def fit(self, X, y):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X): #average of all the word vectors that make up the sentence\n",
        "        return np.array([\n",
        "            np.mean([self.word2vec[w] for w in words if w in self.word2vec]\n",
        "                    or [np.zeros(self.dim)], axis=0)\n",
        "            for words in X\n",
        "        ])\n",
        "\n",
        "run_pipeline(Pipeline([(\"wordVectz\",AverageEmbeddingVectorizer(WordVectorz)),\n",
        "                       (\"multilabel\",ClassifierChain(LogisticRegression()))]),\n",
        "                        X_train, y_train, X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymY0rHax4tpC"
      },
      "source": [
        "##Word embedding (GloVe)\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from nltk import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import tqdm\n",
        "from tqdm import tqdm\n",
        "from numpy import array, asarray, zeros\n",
        "\n",
        "tokenizer = Tokenizer(num_words=5000, lower=True)\n",
        "tokenizer.fit_on_texts(df.new_clean_text_deep_stem)\n",
        "sequences = tokenizer.texts_to_sequences(df.new_clean_text_deep_stem)\n",
        "x = pad_sequences(sequences, maxlen=200)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, \n",
        "                                                    df[df.columns[1:]],\n",
        "                                                    test_size=0.3, \n",
        "                                                    random_state=seeds[4])\n",
        "        \n",
        "embeddings_dictionary = dict()\n",
        "glove_file = open('glove.6B.100d.txt', encoding=\"utf8\")\n",
        "for line in glove_file:\n",
        "    records = line.split()\n",
        "    word = records[0]\n",
        "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
        "    embeddings_dictionary[word] = vector_dimensions\n",
        "glove_file.close()\n",
        "\n",
        "def sent2vec(s):\n",
        "    words = str(s).lower()\n",
        "    words = word_tokenize(words)\n",
        "    M = []\n",
        "    for w in words:\n",
        "        try:\n",
        "            M.append(embeddings_dictionary[w])\n",
        "        except:\n",
        "            continue\n",
        "    M = np.array(M)\n",
        "    v = M.sum(axis=0)\n",
        "    if type(v) != np.ndarray:\n",
        "        return np.zeros(300)\n",
        "    return v / np.sqrt((v ** 2).sum())\n",
        "\n",
        "X_train = [sent2vec(x) for x in tqdm(X_train)]\n",
        "X_test = [sent2vec(x) for x in tqdm(X_test)]\n",
        "\n",
        "run_pipeline(Pipeline([('clf', ClassifierChain(LogisticRegression()))]),\n",
        "             X_train, y_train, X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKvvsmDo1smF"
      },
      "source": [
        "**4.3 Results (ML)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "7qqnuXadgztH",
        "outputId": "b90d129b-7e7e-4f02-9371-54c3532305fd"
      },
      "source": [
        "arrays = [[\"OneVsRest\", \"OneVsRest\", \"OneVsRest\", \"OneVsRest\", \"ClassifierChain\", \"ClassifierChain\", \"ClassifierChain\", \"ClassifierChain\", \"MultiOutputClassifier\", \"MultiOutputClassifier\", \"MultiOutputClassifier\", \"MultiOutputClassifier\"],\n",
        "          [\"BOW\", \"TF-IDF\", \"Word2Vec\", \"GloVe\", \"BOW\", \"TF-IDF\", \"Word2Vec\", \"GloVe\", \"BOW\", \"TF-IDF\", \"Word2Vec\", \"GloVe\", \"BOW\", \"TF-IDF\", \"Word2Vec\", \"GloVe\"],\n",
        "          ]\n",
        "\n",
        "tuples = list(zip(*arrays))\n",
        "index = pd.MultiIndex.from_tuples(tuples, names=['', ''])\n",
        "results = pd.DataFrame(pd.Series(\"\", index=index))\n",
        "\n",
        "results = results.assign(MultinomialNB = (.77,.63,'-','-',\n",
        "                                   .77,.64,'-','-',\n",
        "                                   .77,.63,'-','-'), \n",
        "                  LogisticRegression = (.74,.69,.51,.50,\n",
        "                                        .75,.69,.50,.50,\n",
        "                                        .74,.69,.51,.50), \n",
        "                  LinearSVC = (.77,.75,.52,.51,\n",
        "                               .76,.75,.50,.49,\n",
        "                               .76,.75,.51,.51), \n",
        "                  RandomForest = (.74,.73,.58,.59,\n",
        "                                  .71,.73,.57,.58,\n",
        "                                  .74,.73,.58,.59),\n",
        "                  XGBoost = (.70,.69,.55,'-',\n",
        "                             .70,.73,.53,.54,\n",
        "                             .70,.69,.54,.56))\n",
        "results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>MultinomialNB</th>\n",
              "      <th>LogisticRegression</th>\n",
              "      <th>LinearSVC</th>\n",
              "      <th>RandomForest</th>\n",
              "      <th>XGBoost</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"4\" valign=\"top\">OneVsRest</th>\n",
              "      <th>BOW</th>\n",
              "      <td></td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TF-IDF</th>\n",
              "      <td></td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Word2Vec</th>\n",
              "      <td></td>\n",
              "      <td>-</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GloVe</th>\n",
              "      <td></td>\n",
              "      <td>-</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.59</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"4\" valign=\"top\">ClassifierChain</th>\n",
              "      <th>BOW</th>\n",
              "      <td></td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TF-IDF</th>\n",
              "      <td></td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Word2Vec</th>\n",
              "      <td></td>\n",
              "      <td>-</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GloVe</th>\n",
              "      <td></td>\n",
              "      <td>-</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"4\" valign=\"top\">MultiOutputClassifier</th>\n",
              "      <th>BOW</th>\n",
              "      <td></td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TF-IDF</th>\n",
              "      <td></td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Word2Vec</th>\n",
              "      <td></td>\n",
              "      <td>-</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GloVe</th>\n",
              "      <td></td>\n",
              "      <td>-</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.56</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               0 MultinomialNB  ...  RandomForest  XGBoost\n",
              "                                                ...                       \n",
              "OneVsRest             BOW         0.77          ...  0.74          0.7    \n",
              "                      TF-IDF      0.63          ...  0.73          0.69   \n",
              "                      Word2Vec    -             ...  0.58          0.55   \n",
              "                      GloVe       -             ...  0.59          -      \n",
              "ClassifierChain       BOW         0.77          ...  0.71          0.7    \n",
              "                      TF-IDF      0.64          ...  0.73          0.73   \n",
              "                      Word2Vec    -             ...  0.57          0.53   \n",
              "                      GloVe       -             ...  0.58          0.54   \n",
              "MultiOutputClassifier BOW         0.77          ...  0.74          0.7    \n",
              "                      TF-IDF      0.63          ...  0.73          0.69   \n",
              "                      Word2Vec    -             ...  0.58          0.54   \n",
              "                      GloVe       -             ...  0.59          0.56   \n",
              "\n",
              "[12 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODW3rwdzoBWY"
      },
      "source": [
        "**4.2 Deep Learning**\n",
        "\n",
        "This technique normally gives a performance boost in NLP tasks, e.g., sentiment analysis. It is possible to either train the WordEmbedding layer or use a pre-trained one through transfer learning, such as word2vec and GloVe.\n",
        "\n",
        "Class weights were calculated to address the imbalance problem in the categories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "hbZ4q11soBok",
        "outputId": "11f0ab7c-f2ae-40c0-e92f-171931c83b51"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import keras.models\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Embedding, SpatialDropout1D, Flatten, Dense, LSTM, GlobalMaxPool1D, Activation, Conv1D, Input, Bidirectional\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from keras.optimizers import Adam\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from numpy import zeros\n",
        "\n",
        "tokenizer = Tokenizer(num_words=5000, lower=True) #for details of 'num_words', see https://stackoverflow.com/questions/61760508/how-to-choose-num-words-parameter-for-keras-tokenizer\n",
        "tokenizer.fit_on_texts(df.new_clean_text_deep_stem)\n",
        "sequences = tokenizer.texts_to_sequences(df.new_clean_text_deep_stem)\n",
        "x = pad_sequences(sequences, maxlen=200)\n",
        "print('Shape of data tensor:', x.shape)\n",
        "\n",
        "seeds = [1, 43, 678, 90, 135]\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, \n",
        "                                                    df[df.columns[1:]],\n",
        "                                                    test_size=0.3, \n",
        "                                                    random_state=seeds[0])\n",
        "print(X_train.shape,y_train.shape)\n",
        "print(X_test.shape,y_test.shape)\n",
        "\n",
        "most_common_cat = pd.DataFrame()\n",
        "most_common_cat['cat'] = df.columns[1:]\n",
        "most_common_cat['count'] = df.iloc[:,1:].sum().values\n",
        "most_common_cat.sort_values(['count'], inplace=True, ascending=False)\n",
        "most_common_cat.reset_index(inplace=True, drop=True)\n",
        "\n",
        "most_common_cat['class_weight'] = len(most_common_cat) / most_common_cat['count']\n",
        "class_weight = {}\n",
        "for index, label in enumerate(labels):\n",
        "    class_weight[index] = most_common_cat[most_common_cat['cat'] == labels]['class_weight'].values[0]\n",
        "    \n",
        "most_common_cat.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of data tensor: (25794, 200)\n",
            "(18055, 200) (18055, 11)\n",
            "(7739, 200) (7739, 11)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cat</th>\n",
              "      <th>count</th>\n",
              "      <th>class_weight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>non-moral</td>\n",
              "      <td>11853</td>\n",
              "      <td>0.000928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>harm</td>\n",
              "      <td>2791</td>\n",
              "      <td>0.003941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cheating</td>\n",
              "      <td>2723</td>\n",
              "      <td>0.004040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>care</td>\n",
              "      <td>2116</td>\n",
              "      <td>0.005198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>fairness</td>\n",
              "      <td>1899</td>\n",
              "      <td>0.005793</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         cat  count  class_weight\n",
              "0  non-moral  11853  0.000928    \n",
              "1  harm       2791   0.003941    \n",
              "2  cheating   2723   0.004040    \n",
              "3  care       2116   0.005198    \n",
              "4  fairness   1899   0.005793    "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyC1GEQPlWAu"
      },
      "source": [
        "**4.2.1 DNN**\n",
        "\n",
        "Started with a simple model which only consists of an embedding layer, a dropout layer to reduce the size and prevent overfitting, a max-pooling layer, and one dense layer with a sigmoid activation to produce probabilities for each of the categories that we want to predict.\n",
        "\n",
        "**4.2.2 CNN**\n",
        "\n",
        "Convolutional Neural Networks recognize local patterns in a sequence by processing multiple words at the same time, and 1D convolutional networks are suitable for text processing tasks. In this case, the convolutional layer uses a window size of 3 and learns word sequences that can later be recognized in any position of a text.\n",
        "\n",
        "**4.2.3 LSTM**\n",
        "\n",
        "LSTM (Long short-term memory) are designed to make use of sequential data, when the current step has some kind of relation with the previous steps. This makes them ideal for applications with a time component (audio, time-series data) and natural language processing. LSTM’s perform very well for applications where sequential information is clearly important, because the meaning could be misinterpreted or the grammar could be incorrect if sequential information is not used. Applications include image captioning, language modeling and machine translation.\n",
        "\n",
        "While convolutional neural network (CNN) models use convolutional layers and maximum pooling or max-overtime pooling layers to extract higher-level features, LSTM models can capture long-term dependencies between word sequences hence are better used for text classification (Jang et al., 2020 Bi-LSTM Model to Increase Accuracy in Text\n",
        "Classification: Combining Word2vec CNN and\n",
        "Attention Mechanism; for more details, see [link text](https://www.kdnuggets.com/2019/08/deep-learning-nlp-explained.html)).\n",
        "\n",
        "*   Keras Embedding Layer (output_dim): start with 32. Improvement --> 64. Improvement --> 128 (for more details, see [link text](https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/)).\n",
        "*   Word Embedding: No improvement --> GloVe (0.937); No further improvement --> Word2Vec (0.902).\n",
        "*   The number of units in the LSTM: start with 32. Improvement --> 128. No further improvement --> 256 (for details, see [link text](https://stackoverflow.com/questions/54853138/how-to-set-the-length-of-input-layer-in-lstm)).\n",
        "*   Dropout: start with 0.1. Improvement --> 0.2.\n",
        "*   Recurrent Dropout: start with 0.0. No further improvement --> 0.2.\n",
        "*   Dense layer: start with model.add(Dense(num_classes, activation='sigmoid'))\n",
        ". No further improvoment --> add multiple layers.\n",
        "*   Data shuffling: a strong regularizer, shuffle batch samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JbgcTEfhUR6"
      },
      "source": [
        "num_classes = y_train.shape[1]\n",
        "max_words = len(tokenizer.word_index) + 1 \n",
        "maxlen = 200\n",
        "filter_length = 300\n",
        "\n",
        "def getModel_dnn():\n",
        "    model = Sequential([\n",
        "        Embedding(max_words, 20, input_length=maxlen),\n",
        "        GlobalMaxPool1D(),\n",
        "        Dense(num_classes, activation='sigmoid'), \n",
        "    ],                                            \n",
        "    name=\"DNN_Model\")\n",
        "    return model\n",
        "\n",
        "def getModel_cnn():\n",
        "    model = Sequential([\n",
        "        Embedding(max_words, 128, input_length=maxlen),\n",
        "        Conv1D(filter_length, 3, padding='valid', activation='relu', strides=1), #relu for learning non-liner decision boundaries\n",
        "        GlobalMaxPool1D(),\n",
        "        Dense(num_classes, activation='sigmoid'),\n",
        "    ],\n",
        "    name=\"CNN_Model\")\n",
        "    return model\n",
        "\n",
        "def getModel_lstm():\n",
        "    model = Sequential([\n",
        "        Embedding(max_words, 128, input_length=maxlen), #embed each integer in a 128-dimensional vector\n",
        "        SpatialDropout1D(0.2),\n",
        "        LSTM(128, dropout=0.2, recurrent_dropout=0.0),\n",
        "        Dense(num_classes, activation='sigmoid'), #output layer will have 11 neurons (equal to the number of labels); #sigmoid activation function to predict the probability for each class independently\n",
        "    ],\n",
        "    name=\"LSTM_Model\")\n",
        "    return model\n",
        "\n",
        "##LSTM (GloVe)\n",
        "embedding_matrix_gv = zeros((max_words, 100))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_dictionary.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix_gv[index] = embedding_vector\n",
        "\n",
        "def getModel_lstm_glove():\n",
        "    embedding_layer = Embedding(max_words, 100, weights=[embedding_matrix_gv], trainable=False)\n",
        "    model = Sequential([\n",
        "        embedding_layer,\n",
        "        LSTM(128, dropout=0.2, recurrent_dropout=0.0),\n",
        "        Dense(num_classes, activation='sigmoid'),\n",
        "    ],\n",
        "    name=\"LSTM_GloVe_Model\")\n",
        "    return model\n",
        "\n",
        "#getModel_dnn vs. getModel_cnn vs. getModel_lstm vs. getModel_lstm_glove\n",
        "training_model = getModel_lstm_glove() \n",
        "training_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[tf.keras.metrics.AUC()]) # since we have converted into a n-binary classification problem, here we use binary-crosstropy loss; see https://towardsdatascience.com/choosing-the-right-hyperparameters-for-a-simple-lstm-using-keras-f8e9ed76f046\n",
        "\n",
        "callbacks = [\n",
        "    ReduceLROnPlateau(),\n",
        "    ModelCheckpoint(filepath='model-conv1d.h5', save_best_only=True)\n",
        "]\n",
        "\n",
        "history = training_model.fit(X_train, y_train,\n",
        "                    class_weight=class_weight,\n",
        "                    epochs=30,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.3,\n",
        "                    callbacks=callbacks)\n",
        "\n",
        "metrics = training_model.evaluate(X_test, y_test)\n",
        "print(\"{}: {}\".format(training_model.metrics_names[1], metrics[1]))\n",
        "\n",
        "# serialize model to JSON\n",
        "#lstm_model_json = training_model.to_json()\n",
        "#with open(\"lstm_model.json\", \"w\") as json_file:\n",
        "#    json_file.write(lstm_model_json)\n",
        "# serialize weights to HDF5\n",
        "#training_model.save_weights(\"lstm_model.h5\")\n",
        "#print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFADpLFwb1LS"
      },
      "source": [
        "**LSTM with Word2Vec/GloVe**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNwfPixH18Lq"
      },
      "source": [
        "##LSTM (Word2Vec)\n",
        "#X_train, X_test, y_train, y_test = train_test_split(df['new_clean_text_deep_stem'], \n",
        "#                                                    df.drop(['new_clean_text_deep_stem'], axis=1),\n",
        "#                                                    test_size=0.3, \n",
        "#                                                    random_state=seeds[4],\n",
        "#                                                    shuffle=True)\n",
        "\n",
        "Embedding_dimensions = 100\n",
        "Word2vec_train_data = list(map(lambda x: x.split(), X_train))\n",
        "word2vec_model = Word2Vec(Word2vec_train_data,\n",
        "                size=100, window=5, min_count=10, workers=8)\n",
        "\n",
        "vocab_length = 60000\n",
        "tokenizer = Tokenizer(num_words=5000, lower=True)\n",
        "tokenizer.fit_on_texts(df.new_clean_text_deep_stem)\n",
        "tokenizer.num_words = vocab_length\n",
        "\n",
        "X_train = pad_sequences(tokenizer.texts_to_sequences(X_train), maxlen=200)\n",
        "X_test  = pad_sequences(tokenizer.texts_to_sequences(X_test) , maxlen=200)\n",
        "\n",
        "embedding_matrix_2 = zeros((max_words, 100))\n",
        "\n",
        "for word, token in tokenizer.word_index.items():\n",
        "    if word2vec_model.wv.__contains__(word):\n",
        "        embedding_matrix_2[token] = word2vec_model.wv.__getitem__(word)\n",
        "\n",
        "def getModel_lstm_w2():\n",
        "    embedding_layer = Embedding(max_words, 100, weights=[embedding_matrix_2], trainable=False)\n",
        "    model = Sequential([\n",
        "        embedding_layer,\n",
        "        Bidirectional(LSTM(128, dropout=0.2, recurrent_dropout=0.0)),\n",
        "        Dense(num_classes, activation='sigmoid'),\n",
        "    ],\n",
        "    name=\"LSTM_Word2Vec_Model\")\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZMsP3PeqNYH"
      },
      "source": [
        "**Conclusion** \n",
        "\n",
        "The results table is the performance of each algorithm with five different seeds to mitigate the split bias.\n",
        "\n",
        "Based on the benchmark, the Deep Neural Network showed the best AUC score, but the difference is minimal among the deep learning models, and the CNN and the LSTM have similar performances.\n",
        "\n",
        "CNN’s are good at extracting local and position-invariant features whereas LSTM's are better when classification is determined by a long range semantic dependency rather than some local key-phrases. For tasks where feature detection in text is more important, for example, searching for spam terms, named entities etc. CNN’s work well whereas for tasks where sequential modeling is more important, LSTM's work better.\n",
        "\n",
        "https://journals.sagepub.com/doi/pdf/10.1177/1948550619876629"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "ltL6wBG-XLr1",
        "outputId": "be27f8df-f2b3-4bc1-feee-1c50b85e7785"
      },
      "source": [
        "results.assign(DNN_Average = (\"\",\"\",\"\",\"\",\n",
        "                                \"\",\"\",\"\",\"\",\n",
        "                                \"\",\"\",\"\",.90), \n",
        "                         CNN_Average = (\"\",\"\",\"\",\"\",\n",
        "                                \"\",\"\",\"\",\"\",\n",
        "                                \"\",\"\",\"\",.96), \n",
        "                         LSTM_Average = (\"\",\"\",\"\",\"\",\n",
        "                                 \"\",\"\",\"\",\"\",\n",
        "                                 \"\",\"\",\"\",.96))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>MultinomialNB</th>\n",
              "      <th>LogisticRegression</th>\n",
              "      <th>LinearSVC</th>\n",
              "      <th>RandomForest</th>\n",
              "      <th>XGBoost</th>\n",
              "      <th>DNN_Average</th>\n",
              "      <th>CNN_Average</th>\n",
              "      <th>LSTM_Average</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"4\" valign=\"top\">OneVsRest</th>\n",
              "      <th>BOW</th>\n",
              "      <td></td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.7</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TF-IDF</th>\n",
              "      <td></td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.69</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Word2Vec</th>\n",
              "      <td></td>\n",
              "      <td>-</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.55</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GloVe</th>\n",
              "      <td></td>\n",
              "      <td>-</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.59</td>\n",
              "      <td>-</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"4\" valign=\"top\">ClassifierChain</th>\n",
              "      <th>BOW</th>\n",
              "      <td></td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.7</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TF-IDF</th>\n",
              "      <td></td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.73</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Word2Vec</th>\n",
              "      <td></td>\n",
              "      <td>-</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.53</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GloVe</th>\n",
              "      <td></td>\n",
              "      <td>-</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.54</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"4\" valign=\"top\">MultiOutputClassifier</th>\n",
              "      <th>BOW</th>\n",
              "      <td></td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.7</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TF-IDF</th>\n",
              "      <td></td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.69</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Word2Vec</th>\n",
              "      <td></td>\n",
              "      <td>-</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.54</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GloVe</th>\n",
              "      <td></td>\n",
              "      <td>-</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.96</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               0 MultinomialNB  ...  CNN_Average  LSTM_Average\n",
              "                                                ...                           \n",
              "OneVsRest             BOW         0.77          ...                           \n",
              "                      TF-IDF      0.63          ...                           \n",
              "                      Word2Vec    -             ...                           \n",
              "                      GloVe       -             ...                           \n",
              "ClassifierChain       BOW         0.77          ...                           \n",
              "                      TF-IDF      0.64          ...                           \n",
              "                      Word2Vec    -             ...                           \n",
              "                      GloVe       -             ...                           \n",
              "MultiOutputClassifier BOW         0.77          ...                           \n",
              "                      TF-IDF      0.63          ...                           \n",
              "                      Word2Vec    -             ...                           \n",
              "                      GloVe       -             ...  0.96         0.96        \n",
              "\n",
              "[12 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    }
  ]
}